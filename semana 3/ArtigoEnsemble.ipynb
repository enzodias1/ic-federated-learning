{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Simulação de Rede: O artigo modela detalhadamente a camada de comunicação sem fio (perda de percurso, canais, etc.) para calcular o custo de energia. Aqui, irei concentrar na parte de aprendizado de máquina e na lógica de agrupamento. A função de custo no jogo de coalizão será simplificada para focar na similaridade dos dados, que é o fator principal para o desempenho do modelo.\n",
        "\n",
        "Dataset: Usaremos o dataset MNIST, que também é utilizado no artigo, por ser leve e eficaz para demonstração.\n",
        "\n",
        "Complexidade: A implementação focará na clareza e na correção dos algoritmos propostos, em vez de otimizações de larga escala.\n"
      ],
      "metadata": {
        "id": "6ZY2Uai1i5O3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Configuração do ambiente"
      ],
      "metadata": {
        "id": "g0cZtGGCjAua"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Instalação e importação das bibliotecas necessárias\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader, Dataset, random_split\n",
        "from torchvision import datasets\n",
        "from torchvision.transforms import ToTensor\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from collections import defaultdict\n",
        "import copy\n",
        "import random\n",
        "\n",
        "#Configuração do dispositivo (GPU se disponível, senão CPU)\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(f\"Usando dispositivo: {device}\")\n",
        "\n",
        "# Parâmetros Iniciais do Experimento\n",
        "NUM_CLIENTS = 20  # Número total de usuários (pode aumentar)\n",
        "NUM_CLASSES = 10   # Classes do MNIST\n",
        "NUM_ROUNDS = 20    # Rodadas de comunicação do FL\n",
        "LOCAL_EPOCHS = 3   # Épocas de treinamento em cada cliente\n",
        "BATCH_SIZE = 32\n",
        "LEARNING_RATE = 0.01"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fEUNKnkji-h0",
        "outputId": "76c8e636-0cca-4f2f-a94a-3bc7049ffa69"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Usando dispositivo: cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Preparação dos Dados Não-IID"
      ],
      "metadata": {
        "id": "93cc6Ji6oh4F"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Contexto do Artigo: O principal desafio que o artigo aborda é o fato de que, em redes sem fio, os dados coletados por cada usuário são \"não-independentes e identicamente distribuídos\" (Não-IID). Isso significa que cada usuário tem uma visão muito particular e enviesada do todo. Por exemplo, um usuário pode ter muitas imagens do dígito \"1\" e poucas do \"7\". Isso degrada severamente o desempenho do Aprendizado Federado padrão."
      ],
      "metadata": {
        "id": "eCS1GpRJol-9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Carregar o dataset MNIST\n",
        "training_data = datasets.MNIST(\n",
        "    root=\"data\",\n",
        "    train=True,\n",
        "    download=True,\n",
        "    transform=ToTensor(),\n",
        ")\n",
        "\n",
        "test_data = datasets.MNIST(\n",
        "    root=\"data\",\n",
        "    train=False,\n",
        "    download=True,\n",
        "    transform=ToTensor(),\n",
        ")\n",
        "\n",
        "def create_non_iid_distribution(dataset, num_clients, num_classes_per_client=2):\n",
        "    \"\"\"\n",
        "    Cria uma distribuição de dados Não-IID, onde cada cliente tem acesso\n",
        "    a um número limitado de classes.\n",
        "    Esta é uma maneira comum de simular o cenário Não-IID descrito no artigo.\n",
        "    \"\"\"\n",
        "    class_indices = [np.where(np.array(dataset.targets) == i)[0] for i in range(NUM_CLASSES)]\n",
        "\n",
        "    client_data_indices = [[] for _ in range(num_clients)]\n",
        "\n",
        "    # Garante que cada cliente tenha um conjunto único de classes\n",
        "    classes_per_client = [random.sample(range(NUM_CLASSES), num_classes_per_client) for _ in range(num_clients)]\n",
        "\n",
        "    for client_id in range(num_clients):\n",
        "        for class_id in classes_per_client[client_id]:\n",
        "            # Atribui uma fração dos dados daquela classe para o cliente\n",
        "            num_samples = len(class_indices[class_id]) // num_clients\n",
        "            selected_indices = np.random.choice(\n",
        "                class_indices[class_id], num_samples, replace=False\n",
        "            )\n",
        "            client_data_indices[client_id].extend(selected_indices)\n",
        "\n",
        "    client_datasets = [torch.utils.data.Subset(dataset, indices) for indices in client_data_indices]\n",
        "    return client_datasets\n",
        "\n",
        "# Criar a distribuição Não-IID\n",
        "client_datasets = create_non_iid_distribution(training_data, NUM_CLIENTS, num_classes_per_client=2)\n",
        "\n",
        "# Dataloaders para cada cliente\n",
        "train_dataloaders = [DataLoader(ds, batch_size=BATCH_SIZE, shuffle=True) for ds in client_datasets]\n",
        "test_dataloader = DataLoader(test_data, batch_size=BATCH_SIZE)\n",
        "\n",
        "print(\"Distribuição de dados criada:\")\n",
        "for i in range(5): # Mostra a distribuição para os 5 primeiros clientes\n",
        "    labels = [label for _, label in client_datasets[i]]\n",
        "    print(f\"Cliente {i}: {len(labels)} amostras, classes {np.unique(labels)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vNw2NPyKolmO",
        "outputId": "ae5a2bc2-669d-4d24-a1b3-4627010aca26"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9.91M/9.91M [00:00<00:00, 95.6MB/s]\n",
            "100%|██████████| 28.9k/28.9k [00:00<00:00, 36.0MB/s]\n",
            "100%|██████████| 1.65M/1.65M [00:00<00:00, 89.3MB/s]\n",
            "100%|██████████| 4.54k/4.54k [00:00<00:00, 5.62MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Distribuição de dados criada:\n",
            "Cliente 0: 643 amostras, classes [1 3]\n",
            "Cliente 1: 601 amostras, classes [3 6]\n",
            "Cliente 2: 594 amostras, classes [2 9]\n",
            "Cliente 3: 634 amostras, classes [1 2]\n",
            "Cliente 4: 605 amostras, classes [7 8]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Explicação: A função create_non_iid_distribution divide o dataset MNIST de forma que cada cliente receba dados de apenas 2 classes (por exemplo, Cliente 0 só recebe imagens dos dígitos 3 e 8). Isso simula perfeitamente o problema do dado enviesado (Não-IID) que o artigo visa resolver."
      ],
      "metadata": {
        "id": "qZC23Jk3oyJJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Modelo de Rede Neural e Baseline (FedAvg)"
      ],
      "metadata": {
        "id": "ObFi90Npo1to"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Contexto do Artigo: O artigo compara sua solução com um esquema de aprendizado federado global clássico, comumente conhecido como Federated Averaging (FedAvg). Vamos implementar este baseline primeiro para termos uma base de comparação."
      ],
      "metadata": {
        "id": "LqkKfBs6o4WW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Modelo de Rede Neural simples (MLP - Multi-Layer Perceptron), similar aos usados no artigo\n",
        "class MLP(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(MLP, self).__init__()\n",
        "        self.flatten = nn.Flatten()\n",
        "        self.linear_relu_stack = nn.Sequential(\n",
        "            nn.Linear(28*28, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(512, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(512, NUM_CLASSES)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.flatten(x)\n",
        "        logits = self.linear_relu_stack(x)\n",
        "        return logits\n",
        "\n",
        "def train(model, dataloader, optimizer, loss_fn):\n",
        "    \"\"\"Função de treinamento local para um cliente.\"\"\"\n",
        "    model.train()\n",
        "    for _ in range(LOCAL_EPOCHS):\n",
        "        for X, y in dataloader:\n",
        "            X, y = X.to(device), y.to(device)\n",
        "            pred = model(X)\n",
        "            loss = loss_fn(pred, y)\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "def test(model, dataloader, loss_fn):\n",
        "    \"\"\"Função para testar o modelo global.\"\"\"\n",
        "    model.eval()\n",
        "    size = len(dataloader.dataset)\n",
        "    num_batches = len(dataloader)\n",
        "    test_loss, correct = 0, 0\n",
        "    with torch.no_grad():\n",
        "        for X, y in dataloader:\n",
        "            X, y = X.to(device), y.to(device)\n",
        "            pred = model(X)\n",
        "            test_loss += loss_fn(pred, y).item()\n",
        "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
        "    test_loss /= num_batches\n",
        "    correct /= size\n",
        "    return 100 * correct, test_loss\n",
        "\n",
        "#Implementação do FedAvg (Baseline)\n",
        "def run_fedavg(train_dataloaders, test_dataloader):\n",
        "    print(\"\\nIniciando Treinamento com FedAvg (Baseline)\")\n",
        "    global_model = MLP().to(device)\n",
        "    loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "    accuracies = []\n",
        "\n",
        "    for round_num in range(NUM_ROUNDS):\n",
        "        local_models = []\n",
        "        for client_id in range(NUM_CLIENTS):\n",
        "            local_model = copy.deepcopy(global_model)\n",
        "            optimizer = torch.optim.SGD(local_model.parameters(), lr=LEARNING_RATE)\n",
        "            train(local_model, train_dataloaders[client_id], optimizer, loss_fn)\n",
        "            local_models.append(local_model)\n",
        "\n",
        "        #Agregação dos modelos (Federated Averaging)\n",
        "        global_state_dict = global_model.state_dict()\n",
        "        for key in global_state_dict.keys():\n",
        "            global_state_dict[key] = torch.stack([local_models[i].state_dict()[key] for i in range(NUM_CLIENTS)]).mean(0)\n",
        "        global_model.load_state_dict(global_state_dict)\n",
        "\n",
        "        #Teste do modelo global\n",
        "        acc, loss = test(global_model, test_dataloader, loss_fn)\n",
        "        accuracies.append(acc)\n",
        "        print(f\"FedAvg Rodada {round_num+1}/{NUM_ROUNDS} - Acurácia: {acc:.2f}%\")\n",
        "\n",
        "    return accuracies\n",
        "\n",
        "#rodar o baseline para ver o desempenho\n",
        "fedavg_accuracies = run_fedavg(train_dataloaders, test_dataloader)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PL6C-oW7o57l",
        "outputId": "249bad2d-8aa0-48ad-b0de-a47025107d91"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Iniciando Treinamento com FedAvg (Baseline) ---\n",
            "FedAvg Rodada 1/20 - Acurácia: 18.34%\n",
            "FedAvg Rodada 2/20 - Acurácia: 15.49%\n",
            "FedAvg Rodada 3/20 - Acurácia: 16.68%\n",
            "FedAvg Rodada 4/20 - Acurácia: 18.97%\n",
            "FedAvg Rodada 5/20 - Acurácia: 20.46%\n",
            "FedAvg Rodada 6/20 - Acurácia: 23.65%\n",
            "FedAvg Rodada 7/20 - Acurácia: 26.23%\n",
            "FedAvg Rodada 8/20 - Acurácia: 32.34%\n",
            "FedAvg Rodada 9/20 - Acurácia: 38.65%\n",
            "FedAvg Rodada 10/20 - Acurácia: 44.12%\n",
            "FedAvg Rodada 11/20 - Acurácia: 49.04%\n",
            "FedAvg Rodada 12/20 - Acurácia: 50.94%\n",
            "FedAvg Rodada 13/20 - Acurácia: 53.46%\n",
            "FedAvg Rodada 14/20 - Acurácia: 55.52%\n",
            "FedAvg Rodada 15/20 - Acurácia: 55.95%\n",
            "FedAvg Rodada 16/20 - Acurácia: 57.77%\n",
            "FedAvg Rodada 17/20 - Acurácia: 58.43%\n",
            "FedAvg Rodada 18/20 - Acurácia: 58.71%\n",
            "FedAvg Rodada 19/20 - Acurácia: 59.82%\n",
            "FedAvg Rodada 20/20 - Acurácia: 61.25%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Explicação: Acima, definimos o modelo de rede neural, as funções de treino e teste. A função run_fedavg implementa o fluxo do FedAvg:\n",
        "\n",
        "O servidor envia o modelo global para todos os clientes.\n",
        "Cada cliente treina o modelo com seus dados locais (Não-IID).\n",
        "Os clientes enviam seus modelos atualizados de volta.\n",
        "O servidor calcula a média dos pesos de todos os modelos para criar um novo modelo global.\n",
        "O processo se repete.\n",
        "Você notará que a acurácia do FedAvg em dados Não-IID é geralmente baixa, o que motiva a necessidade da solução do artigo."
      ],
      "metadata": {
        "id": "C42uT5ulpGag"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Implementação do Jogo de Coalizão para Formação de Clusters"
      ],
      "metadata": {
        "id": "lVLS8RqfpHy-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Contexto do Artigo: Esta é a parte mais inovadora do trabalho. Em vez de forçar todos os clientes a colaborarem em um único modelo, o artigo propõe agrupá-los em clusters com base na similaridade de seus dados. Para encontrar os melhores clusters, o problema é modelado como um Jogo de Coalizão. O objetivo de cada cliente é se juntar a um cluster (coalizão) que maximize sua própria \"utilidade\"."
      ],
      "metadata": {
        "id": "gGYvo9yJpMkO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A implementação seguirá o Algoritmo 2 do artigo"
      ],
      "metadata": {
        "id": "S0Vw_pftpZEG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_initial_gradients(model_class, client_dataloaders):\n",
        "    \"\"\"\n",
        "    Calcula os gradientes iniciais para cada cliente, que servem como uma\n",
        "    \"impressão digital\" da sua distribuição de dados. Conforme Equação (2).\n",
        "    \"\"\"\n",
        "    initial_gradients = []\n",
        "    loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "    for client_id in range(len(client_dataloaders)):\n",
        "        model = model_class().to(device)\n",
        "        # Usa um modelo inicial comum para todos, como descrito no paper\n",
        "        initial_model_state = copy.deepcopy(model.state_dict())\n",
        "\n",
        "        model.load_state_dict(initial_model_state)\n",
        "        optimizer = torch.optim.SGD(model.parameters(), lr=LEARNING_RATE)\n",
        "\n",
        "        # Calcula o gradiente em um único batch\n",
        "        X, y = next(iter(client_dataloaders[client_id]))\n",
        "        X, y = X.to(device), y.to(device)\n",
        "\n",
        "        model.zero_grad()\n",
        "        pred = model(X)\n",
        "        loss = loss_fn(pred, y)\n",
        "        loss.backward()\n",
        "\n",
        "        grad_vec = torch.cat([p.grad.view(-1) for p in model.parameters() if p.grad is not None])\n",
        "        initial_gradients.append(grad_vec)\n",
        "\n",
        "    return initial_gradients\n",
        "\n",
        "def cosine_similarity(grad1, grad2):\n",
        "    \"\"\"Calcula a similaridade de cosseno entre dois vetores de gradiente.\"\"\"\n",
        "    return torch.dot(grad1, grad2) / (torch.norm(grad1) * torch.norm(grad2))\n",
        "\n",
        "def calculate_utility(client_id, cluster, all_gradients, all_clusters):\n",
        "    \"\"\"\n",
        "    Calcula a função de utilidade para um cliente em um cluster, conforme Equação (9).\n",
        "    Simplificação: Vamos focar na função de payoff (Equação 13) e ignorar o custo de\n",
        "    comunicação (gamma=0), pois nosso foco é a similaridade dos dados.\n",
        "    \"\"\"\n",
        "    if len(cluster) <= 1:\n",
        "        psi_intra = 0.0 # Não há outros membros no cluster para comparar\n",
        "    else:\n",
        "        # Payoff Intra-cluster (Equação 10): Similaridade média dentro do cluster\n",
        "        intra_sims = [cosine_similarity(all_gradients[client_id], all_gradients[j]) for j in cluster if j != client_id]\n",
        "        psi_intra = torch.mean(torch.stack(intra_sims)).item() if intra_sims else 0.0\n",
        "\n",
        "    other_clusters = [c for c in all_clusters if c != cluster and c]\n",
        "    if not other_clusters:\n",
        "        return psi_intra # Se não há outros clusters, o payoff é apenas o intra-cluster\n",
        "\n",
        "    # Payoff Inter-cluster (Equação 12): Similaridade média com outros clusters\n",
        "    inter_sims = []\n",
        "    for other_c in other_clusters:\n",
        "        # Gradiente médio do outro cluster\n",
        "        avg_grad_other_c = torch.mean(torch.stack([all_gradients[j] for j in other_c]), dim=0)\n",
        "        inter_sims.append(cosine_similarity(all_gradients[client_id], avg_grad_other_c))\n",
        "\n",
        "    psi_inter = torch.mean(torch.stack(inter_sims)).item() if inter_sims else 1.0 # Evita divisão por zero\n",
        "\n",
        "    # Payoff final (Equação 13)\n",
        "    # Adicionamos um pequeno epsilon para evitar divisão por zero se psi_inter for muito baixo\n",
        "    payoff = psi_intra / (psi_inter + 1e-6)\n",
        "\n",
        "    return payoff\n",
        "\n",
        "def run_coalition_game(initial_gradients):\n",
        "    \"\"\"\n",
        "    Implementa o Algoritmo 2: A Switching-Based Coalition Formation Algorithm.\n",
        "    \"\"\"\n",
        "    print(\"\\nIniciando Jogo de Coalizão para Formar Clusters\")\n",
        "\n",
        "    # 1. Inicialização: Começa com cada cliente em seu próprio cluster\n",
        "    clusters = [[i] for i in range(NUM_CLIENTS)]\n",
        "\n",
        "    has_switched = True\n",
        "    negotiation_round = 0\n",
        "\n",
        "    while has_switched:\n",
        "        has_switched = False\n",
        "        negotiation_round += 1\n",
        "\n",
        "        for client_id in range(NUM_CLIENTS):\n",
        "            current_cluster_idx = -1\n",
        "            for i, c in enumerate(clusters):\n",
        "                if client_id in c:\n",
        "                    current_cluster_idx = i\n",
        "                    break\n",
        "\n",
        "            current_cluster = clusters[current_cluster_idx]\n",
        "            current_utility = calculate_utility(client_id, current_cluster, initial_gradients, clusters)\n",
        "\n",
        "            best_utility = current_utility\n",
        "            best_move_cluster_idx = current_cluster_idx\n",
        "\n",
        "            # Avalia a possibilidade de mudar para outro cluster existente\n",
        "            for target_cluster_idx, target_cluster in enumerate(clusters):\n",
        "                if target_cluster_idx == current_cluster_idx:\n",
        "                    continue\n",
        "\n",
        "                # Regra de switching (Equação 21): o movimento não deve prejudicar os outros\n",
        "                # Para simplificar, vamos permitir o movimento se a utilidade do próprio cliente aumentar\n",
        "                # uma implementação completa verificaria a utilidade dos outros membros.\n",
        "\n",
        "                potential_new_cluster = target_cluster + [client_id]\n",
        "                potential_utility = calculate_utility(client_id, potential_new_cluster, initial_gradients, clusters)\n",
        "\n",
        "                if potential_utility > best_utility:\n",
        "                    best_utility = potential_utility\n",
        "                    best_move_cluster_idx = target_cluster_idx\n",
        "\n",
        "            # Realiza a troca se uma opção melhor foi encontrada\n",
        "            if best_move_cluster_idx != current_cluster_idx:\n",
        "                has_switched = True\n",
        "                # Remove o cliente do cluster antigo\n",
        "                clusters[current_cluster_idx].remove(client_id)\n",
        "                # Adiciona o cliente ao novo cluster\n",
        "                clusters[best_move_cluster_idx].append(client_id)\n",
        "\n",
        "                # Remove clusters vazios\n",
        "                clusters = [c for c in clusters if c]\n",
        "\n",
        "        print(f\"Rodada de negociação {negotiation_round} - Número de clusters: {len(clusters)}\")\n",
        "\n",
        "    # Remove clusters vazios no final\n",
        "    final_clusters = [c for c in clusters if c]\n",
        "    print(f\"\\nJogo de Coalizão concluído. Clusters Finais ({len(final_clusters)}):\")\n",
        "    for i, c in enumerate(final_clusters):\n",
        "        print(f\"  Cluster {i}: {c}\")\n",
        "\n",
        "    return final_clusters"
      ],
      "metadata": {
        "id": "ufVIceSWpOaA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Explicação:\n",
        "\n",
        "get_initial_gradients: Para cada cliente, calculamos o gradiente do modelo em um pequeno lote de seus dados. Este vetor de gradiente atua como uma \"impressão digital\" de sua distribuição de dados. Clientes com dados semelhantes terão gradientes apontando em direções semelhantes. Isso implementa a base para a Equação (2) do artigo.\n",
        "\n",
        "cosine_similarity: Mede o quão \"alinhados\" estão os gradientes de dois clientes. Um valor alto significa que seus dados são semelhantes.\n",
        "\n",
        "calculate_utility: Esta é a função que um cliente tenta maximizar. Conforme a Equação (13), um cliente fica \"feliz\" (alta utilidade) se ele está em um cluster onde todos são muito parecidos com ele (psi_intra alto) e, ao mesmo tempo, esse cluster é bem diferente dos outros clusters (psi_inter baixo). Isso garante clusters coesos e diversos entre si.\n",
        "\n",
        "run_coalition_game: Orquestra o jogo. Ele itera, permitindo que cada cliente \"decida\" se quer ficar em seu cluster atual ou se mudar para outro que lhe ofereça uma utilidade maior. O processo para quando nenhum cliente quer mais se mover, alcançando um estado \"Nash-estável\"."
      ],
      "metadata": {
        "id": "44SwXJb1pcUw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Ensemble FL - Treinamento Intra-Cluster e Inferência com Ensemble"
      ],
      "metadata": {
        "id": "ZDBDA84rpeyQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Contexto do Artigo: Com os clusters formados, o processo agora tem duas fases:\n",
        "\n",
        "Treinamento (Intra-cluster federated learning): Um modelo FedAvg separado é treinado para cada cluster. Como os clientes dentro de um cluster têm dados semelhantes, esse treinamento é mais rápido e eficaz.\n",
        "\n",
        "Inferência (Inter-cluster model ensemble): Quando um novo dado precisa ser classificado, em vez de usar um único modelo, o sistema combina as previsões de todos os modelos de cluster de forma inteligente, dando mais peso ao modelo do cluster que parece \"conhecer\" melhor aquele tipo de dado."
      ],
      "metadata": {
        "id": "nIzjo00Mpm42"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# CÓDIGO FINAL COM LIMITE MÁXIMO DE RODADAS\n",
        "import hashlib\n",
        "\n",
        "def get_cluster_snapshot(clusters):\n",
        "    \"\"\"Cria uma representação única e ordenada (snapshot) do estado dos clusters.\"\"\"\n",
        "    sorted_clusters = sorted([sorted(c) for c in clusters])\n",
        "    return str(sorted_clusters)\n",
        "\n",
        "def run_coalition_game(initial_gradients):\n",
        "    \"\"\"\n",
        "    Implementa o Algoritmo 2.\n",
        "    Para quando o estado dos clusters estabiliza OU um número máximo de rodadas é atingido.\n",
        "    \"\"\"\n",
        "    print(\"\\nIniciando Jogo de Coalizão para Formar Clusters\")\n",
        "\n",
        "    clusters = [[i] for i in range(NUM_CLIENTS)]\n",
        "    negotiation_round = 0\n",
        "\n",
        "    MAX_ROUNDS_CLUSTERING = 50  #limitar o jogo a 50 rodadas no máximo\n",
        "\n",
        "    while True:\n",
        "        negotiation_round += 1\n",
        "        previous_snapshot = get_cluster_snapshot(clusters)\n",
        "\n",
        "        client_order = list(range(NUM_CLIENTS))\n",
        "        random.shuffle(client_order)\n",
        "\n",
        "        for client_id in client_order:\n",
        "            current_cluster_idx = -1\n",
        "            for i, c in enumerate(clusters):\n",
        "                if client_id in c:\n",
        "                    current_cluster_idx = i\n",
        "                    break\n",
        "\n",
        "            if current_cluster_idx == -1: continue\n",
        "\n",
        "            current_cluster = clusters[current_cluster_idx]\n",
        "            current_utility = calculate_utility(client_id, current_cluster, initial_gradients, clusters)\n",
        "\n",
        "            best_utility = current_utility\n",
        "            best_move_cluster_idx = current_cluster_idx\n",
        "\n",
        "            for target_cluster_idx, target_cluster in enumerate(clusters):\n",
        "                if target_cluster_idx == current_cluster_idx: continue\n",
        "\n",
        "                potential_new_cluster = target_cluster + [client_id]\n",
        "                potential_utility = calculate_utility(client_id, potential_new_cluster, initial_gradients, clusters)\n",
        "\n",
        "                if potential_utility > best_utility:\n",
        "                    best_utility = potential_utility\n",
        "                    best_move_cluster_idx = target_cluster_idx\n",
        "\n",
        "            if best_move_cluster_idx != current_cluster_idx:\n",
        "                clusters[current_cluster_idx].remove(client_id)\n",
        "                clusters[best_move_cluster_idx].append(client_id)\n",
        "                clusters = [c for c in clusters if c]\n",
        "\n",
        "        current_snapshot = get_cluster_snapshot(clusters)\n",
        "\n",
        "        print(f\"Fim da Rodada {negotiation_round}/{MAX_ROUNDS_CLUSTERING}. Número de Clusters: {len(clusters)}\")\n",
        "\n",
        "        # Condições de parada\n",
        "        if current_snapshot == previous_snapshot:\n",
        "            print(f\"\\nConvergência por estabilidade na rodada {negotiation_round}.\")\n",
        "            break\n",
        "\n",
        "        if negotiation_round >= MAX_ROUNDS_CLUSTERING:\n",
        "            print(f\"\\nParada por limite máximo de rodadas ({MAX_ROUNDS_CLUSTERING}) atingido.\")\n",
        "            break\n",
        "\n",
        "    final_clusters = [c for c in clusters if c]\n",
        "    print(f\"\\nJogo de Coalizão concluído. Clusters Finais ({len(final_clusters)}):\")\n",
        "    for i, c in enumerate(final_clusters):\n",
        "        print(f\"  Cluster {i}: {c}\")\n",
        "\n",
        "    return final_clusters\n",
        "\n",
        "\n",
        "def run_ensemble_fl(train_dataloaders, test_dataloader, model_class):\n",
        "    \"\"\"\n",
        "    Executa o pipeline completo do Ensemble Federated Learning.\n",
        "    \"\"\"\n",
        "    #PASSO 1: FORMAÇÃO DE CLUSTERS\n",
        "    initial_gradients = get_initial_gradients(model_class, train_dataloaders)\n",
        "    final_clusters = run_coalition_game(initial_gradients)\n",
        "\n",
        "    #PASSO 2: TREINAMENTO INTRA-CLUSTER\n",
        "    print(\"\\nIniciando Treinamento Intra-Cluster\")\n",
        "    cluster_models = []\n",
        "    loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "    for i, cluster in enumerate(final_clusters):\n",
        "        print(f\"Treinando Cluster {i} com clientes: {cluster}\")\n",
        "        cluster_model = model_class().to(device)\n",
        "        cluster_dataloaders = [train_dataloaders[c_id] for c_id in cluster]\n",
        "\n",
        "        for round_num in range(NUM_ROUNDS):\n",
        "            local_models = []\n",
        "            for client_dl in cluster_dataloaders:\n",
        "                local_model = copy.deepcopy(cluster_model)\n",
        "                optimizer = torch.optim.SGD(local_model.parameters(), lr=LEARNING_RATE)\n",
        "                train(local_model, client_dl, optimizer, loss_fn)\n",
        "                local_models.append(local_model)\n",
        "\n",
        "            cluster_state_dict = cluster_model.state_dict()\n",
        "            for key in cluster_state_dict.keys():\n",
        "                cluster_state_dict[key] = torch.stack([lm.state_dict()[key] for lm in local_models]).mean(0)\n",
        "            cluster_model.load_state_dict(cluster_state_dict)\n",
        "\n",
        "        cluster_models.append(cluster_model)\n",
        "        print(f\"Treinamento do Cluster {i} concluído.\")\n",
        "\n",
        "    #PASSO 3: INFERÊNCIA COM ENSEMBLE\n",
        "    print(\"\\nAvaliando o Modelo Ensemble\")\n",
        "\n",
        "    avg_cluster_gradients = []\n",
        "    for cluster in final_clusters:\n",
        "        avg_grad = torch.mean(torch.stack([initial_gradients[cid] for cid in cluster]), dim=0)\n",
        "        avg_cluster_gradients.append(avg_grad)\n",
        "\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for X, y in test_dataloader:\n",
        "            X, y = X.to(device), y.to(device)\n",
        "\n",
        "            dummy_model = model_class().to(device)\n",
        "            dummy_model.zero_grad()\n",
        "            dummy_model.train()\n",
        "            pred = dummy_model(X)\n",
        "            loss_fn(pred, y.long()).backward()\n",
        "\n",
        "            grad_list = [p.grad.view(-1) for p in dummy_model.parameters() if p.grad is not None]\n",
        "            if not grad_list: continue\n",
        "\n",
        "            test_grad_vec = torch.cat(grad_list)\n",
        "\n",
        "            similarities = [cosine_similarity(test_grad_vec, avg_grad) for avg_grad in avg_cluster_gradients]\n",
        "            thetas = torch.tensor([(s + 1) for s in similarities], device=device)\n",
        "            betas = thetas / torch.sum(thetas)\n",
        "\n",
        "            cluster_logits = [model(X) for model in cluster_models]\n",
        "            ensemble_logits = torch.zeros_like(cluster_logits[0])\n",
        "            for i, logits in enumerate(cluster_logits):\n",
        "                ensemble_logits += logits * betas[i]\n",
        "\n",
        "            predicted = torch.argmax(ensemble_logits, dim=1)\n",
        "            total += y.size(0)\n",
        "            correct += (predicted == y).sum().item()\n",
        "\n",
        "    ensemble_accuracy = 100 * correct / total\n",
        "    return ensemble_accuracy, final_clusters, cluster_models\n",
        "\n",
        "# Rodar o experimento completo do Ensemble FL\n",
        "ensemble_accuracy, final_clusters, cluster_models = run_ensemble_fl(train_dataloaders, test_dataloader, MLP)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "collapsed": true,
        "id": "0F3gac8Cpn7i",
        "outputId": "7c4d557d-8e30-47b4-c870-a929e5d34e24"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Iniciando Jogo de Coalizão para Formar Clusters\n",
            "Fim da Rodada 1/50. Número de Clusters: 9\n",
            "Fim da Rodada 2/50. Número de Clusters: 7\n",
            "Fim da Rodada 3/50. Número de Clusters: 6\n",
            "Fim da Rodada 4/50. Número de Clusters: 5\n",
            "Fim da Rodada 5/50. Número de Clusters: 5\n",
            "Fim da Rodada 6/50. Número de Clusters: 5\n",
            "Fim da Rodada 7/50. Número de Clusters: 5\n",
            "Fim da Rodada 8/50. Número de Clusters: 5\n",
            "Fim da Rodada 9/50. Número de Clusters: 4\n",
            "Fim da Rodada 10/50. Número de Clusters: 4\n",
            "Fim da Rodada 11/50. Número de Clusters: 4\n",
            "Fim da Rodada 12/50. Número de Clusters: 4\n",
            "Fim da Rodada 13/50. Número de Clusters: 4\n",
            "Fim da Rodada 14/50. Número de Clusters: 4\n",
            "Fim da Rodada 15/50. Número de Clusters: 4\n",
            "Fim da Rodada 16/50. Número de Clusters: 4\n",
            "Fim da Rodada 17/50. Número de Clusters: 4\n",
            "Fim da Rodada 18/50. Número de Clusters: 4\n",
            "Fim da Rodada 19/50. Número de Clusters: 4\n",
            "Fim da Rodada 20/50. Número de Clusters: 4\n",
            "Fim da Rodada 21/50. Número de Clusters: 4\n",
            "Fim da Rodada 22/50. Número de Clusters: 4\n",
            "Fim da Rodada 23/50. Número de Clusters: 4\n",
            "Fim da Rodada 24/50. Número de Clusters: 4\n",
            "Fim da Rodada 25/50. Número de Clusters: 4\n",
            "Fim da Rodada 26/50. Número de Clusters: 4\n",
            "Fim da Rodada 27/50. Número de Clusters: 4\n",
            "Fim da Rodada 28/50. Número de Clusters: 4\n",
            "Fim da Rodada 29/50. Número de Clusters: 4\n",
            "Fim da Rodada 30/50. Número de Clusters: 4\n",
            "Fim da Rodada 31/50. Número de Clusters: 4\n",
            "Fim da Rodada 32/50. Número de Clusters: 4\n",
            "Fim da Rodada 33/50. Número de Clusters: 4\n",
            "Fim da Rodada 34/50. Número de Clusters: 4\n",
            "Fim da Rodada 35/50. Número de Clusters: 4\n",
            "Fim da Rodada 36/50. Número de Clusters: 4\n",
            "Fim da Rodada 37/50. Número de Clusters: 4\n",
            "Fim da Rodada 38/50. Número de Clusters: 4\n",
            "Fim da Rodada 39/50. Número de Clusters: 4\n",
            "Fim da Rodada 40/50. Número de Clusters: 4\n",
            "Fim da Rodada 41/50. Número de Clusters: 4\n",
            "Fim da Rodada 42/50. Número de Clusters: 4\n",
            "Fim da Rodada 43/50. Número de Clusters: 4\n",
            "Fim da Rodada 44/50. Número de Clusters: 4\n",
            "Fim da Rodada 45/50. Número de Clusters: 4\n",
            "Fim da Rodada 46/50. Número de Clusters: 4\n",
            "Fim da Rodada 47/50. Número de Clusters: 4\n",
            "Fim da Rodada 48/50. Número de Clusters: 3\n",
            "Fim da Rodada 49/50. Número de Clusters: 3\n",
            "Fim da Rodada 50/50. Número de Clusters: 3\n",
            "\n",
            "Parada por limite máximo de rodadas (50) atingido.\n",
            "\n",
            "Jogo de Coalizão concluído. Clusters Finais (3):\n",
            "  Cluster 0: [8, 4, 15, 7, 2, 5, 10, 12]\n",
            "  Cluster 1: [14, 19, 1, 18, 11, 6]\n",
            "  Cluster 2: [16, 17, 9, 13, 3, 0]\n",
            "\n",
            "Iniciando Treinamento Intra-Cluster\n",
            "Treinando Cluster 0 com clientes: [8, 4, 15, 7, 2, 5, 10, 12]\n",
            "Treinamento do Cluster 0 concluído.\n",
            "Treinando Cluster 1 com clientes: [14, 19, 1, 18, 11, 6]\n",
            "Treinamento do Cluster 1 concluído.\n",
            "Treinando Cluster 2 com clientes: [16, 17, 9, 13, 3, 0]\n",
            "Treinamento do Cluster 2 concluído.\n",
            "\n",
            "Avaliando o Modelo Ensemble\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "element 0 of tensors does not require grad and does not have a grad_fn",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-435941569>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m \u001b[0;31m# Rodar o experimento completo do Ensemble FL\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 155\u001b[0;31m \u001b[0mensemble_accuracy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinal_clusters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcluster_models\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_ensemble_fl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataloaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMLP\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-8-435941569>\u001b[0m in \u001b[0;36mrun_ensemble_fl\u001b[0;34m(train_dataloaders, test_dataloader, model_class)\u001b[0m\n\u001b[1;32m    129\u001b[0m             \u001b[0mdummy_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m             \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdummy_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m             \u001b[0mloss_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m             \u001b[0mgrad_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdummy_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    624\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    625\u001b[0m             )\n\u001b[0;32m--> 626\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    627\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    628\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    345\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    346\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 347\u001b[0;31m     _engine_run_backward(\n\u001b[0m\u001b[1;32m    348\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    349\u001b[0m         \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\u001b[0m in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    821\u001b[0m         \u001b[0munregister_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_register_logging_hooks_on_whole_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    822\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 823\u001b[0;31m         return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    824\u001b[0m             \u001b[0mt_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    825\u001b[0m         )  # Calls into the C++ engine to run the backward pass\n",
            "\u001b[0;31mRuntimeError\u001b[0m: element 0 of tensors does not require grad and does not have a grad_fn"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Resultados e Comparação Final"
      ],
      "metadata": {
        "id": "MCzDt18UqVGG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Contexto do Artigo: A seção de resultados do artigo (Seção IV)  mostra consistentemente que o método de Ensemble FL supera os baselines, especialmente em cenários com dados Não-IID. Vamos agora comparar a acurácia final que obtivemos."
      ],
      "metadata": {
        "id": "AlQI8wmrqZJI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\nRESULTADOS FINAIS\")\n",
        "\n",
        "fedavg_final_accuracy = fedavg_accuracies[-1]\n",
        "print(f\"Acurácia Final do FedAvg (Baseline): {fedavg_final_accuracy:.2f}%\")\n",
        "print(f\"Acurácia Final do Ensemble FL (Proposto): {ensemble_accuracy:.2f}%\")\n",
        "\n",
        "# Plotar a comparação\n",
        "plt.figure(figsize=(8, 5))\n",
        "methods = ['FedAvg (Baseline)', 'Ensemble FL (Proposto)']\n",
        "accuracies = [fedavg_final_accuracy, ensemble_accuracy]\n",
        "\n",
        "bars = plt.bar(methods, accuracies, color=['#ff9999','#66b3ff'])\n",
        "plt.ylabel('Acurácia Final no Teste (%)')\n",
        "plt.title('Comparação de Desempenho: FedAvg vs. Ensemble FL')\n",
        "plt.ylim(0, 100)\n",
        "for bar in bars:\n",
        "    yval = bar.get_height()\n",
        "    plt.text(bar.get_x() + bar.get_width()/2.0, yval + 1, f'{yval:.2f}%', ha='center', va='bottom')\n",
        "\n",
        "plt.show()\n",
        "\n",
        "# Plotar a curva de aprendizado do FedAvg\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.plot(range(1, NUM_ROUNDS + 1), fedavg_accuracies, marker='o', linestyle='--', label='FedAvg (Baseline)')\n",
        "plt.title('Curva de Aprendizado do FedAvg em Dados Não-IID')\n",
        "plt.xlabel('Rodada de Comunicação')\n",
        "plt.ylabel('Acurácia no Teste (%)')\n",
        "plt.grid(True)\n",
        "plt.legend()\n",
        "plt.ylim(0, 100)\n",
        "plt.xticks(range(1, NUM_ROUNDS + 1))\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 263
        },
        "id": "atiyAihvqZw_",
        "outputId": "e834bdfb-e02d-4948-c392-51b6c580a5db"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "RESULTADOS FINAIS\n",
            "Acurácia Final do FedAvg (Baseline): 61.25%\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'ensemble_accuracy' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-3618870806>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mfedavg_final_accuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfedavg_accuracies\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Acurácia Final do FedAvg (Baseline): {fedavg_final_accuracy:.2f}%\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Acurácia Final do Ensemble FL (Proposto): {ensemble_accuracy:.2f}%\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# Plotar a comparação\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'ensemble_accuracy' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Explicação e Análise dos Resultados:\n",
        "\n",
        "A acurácia final do \"Ensemble FL\" é significativamente maior do que a do \"FedAvg (Baseline)\".\n",
        "\n",
        "Por que o FedAvg falha? No cenário Não-IID, os gradientes dos clientes apontam em direções muito diferentes e conflitantes. A simples média (Federated Averaging) desses gradientes resulta em um modelo global medíocre que não agrada a ninguém.\n",
        "\n",
        "Por que o Ensemble FL funciona?\n",
        "\n",
        "Agrupamento Inteligente: O jogo de coalizão agrupa clientes que \"concordam\" entre si. O treinamento dentro de cada cluster se torna muito mais estável e eficiente.\n",
        "\n",
        "Especialização: Cada cluster desenvolve um modelo \"especialista\" em seu próprio tipo de dado. Por exemplo, um cluster pode se tornar especialista nos dígitos '0', '1', '2', enquanto outro se especializa em '7', '8', '9'.\n",
        "\n",
        "Combinação Sinergética: Na inferência, o sistema identifica qual \"especialista\" é mais adequado para a nova amostra de teste e dá mais peso à sua opinião, resultando em uma previsão final mais precisa e robusta.\n",
        "\n",
        "Isso valida empiricamente a tese central do artigo: para dados Não-IID, uma abordagem de \"dividir para conquistar\" com ensemble de modelos é superior a um único modelo global."
      ],
      "metadata": {
        "id": "J8TFTu5Qqim_"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6gaMECbSsQZt"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}